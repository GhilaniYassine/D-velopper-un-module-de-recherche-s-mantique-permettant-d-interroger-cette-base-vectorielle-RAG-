# ğŸ§  Semantic Search Module with ChromaDB

**Production-ready semantic search and document ingestion system** using ChromaDB vector store, sentence transformers, and FastAPI.

## ğŸ¯ Overview

This system implements a complete RAG (Retrieval-Augmented Generation) **retrieval** pipeline supporting:
- **Document Ingestion**: Add documents to the vector store dynamically
- **Semantic Search**: Query documents using natural language similarity
- **REST API**: FastAPI endpoints for search and ingestion
- **Web Interface**: Interactive frontend with real-time results

## ğŸ— Architecture (per agent.md specifications)

### Technology Stack
- **Vector Store**: ChromaDB (persistent, easy to use)
- **Embedding Model**: `all-MiniLM-L6-v2` (384 dimensions, Sentence-Transformers)
- **Similarity**: Cosine similarity (in ChromaDB)
- **API**: FastAPI + Uvicorn
- **Database**: Persistent ChromaDB at `data/chroma_db/`

### Key Features
âœ… **Dynamic document ingestion** via REST API or CLI  
âœ… **Semantic search** with top-3 results  
âœ… **Web interface** for interactive queries  
âœ… **CLI support** for batch operations  
âœ… **Status monitoring** (`/status` endpoint)  
âœ… **Health checks** (`/healthz` endpoint)  

---

## ğŸ“¦ Setup & Installation

### 1. Create Virtual Environment
```bash
python3 -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
```

### 2. Install Dependencies
```bash
pip install -r requirements.txt
```

### 3. Configure Environment
```bash
cp .env.example .env
# .env defaults are already configured for local development
```

---

## ğŸš€ Running the System

### Option A: Start FastAPI Server (Full System)

```bash
python3 -m uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload
```

âœ… **Open in browser**: http://localhost:8000  
âœ… **API documentation**: http://localhost:8000/docs (Swagger UI)  
âœ… **Alternative docs**: http://localhost:8000/redoc (ReDoc)  

### Option B: CLI Mode

#### Search
```bash
python3 -m app.main search -q "What are the recommended dosages for alpha-amylase?"
```

JSON output:
```bash
python3 -m app.main search -q "..." --json
```

#### Ingest from Folder
```bash
python3 -m app.main ingest --folder data/enzymes/
```

#### Check Status
```bash
python3 -m app.main status
```

#### Standalone Ingestion Script
```bash
python3 ingest_documents.py
```

---

## ğŸ”Œ API Endpoints

### Search (Semantic Retrieval)
**POST** `/search`

Request:
```bash
curl -X POST http://localhost:8000/search \
  -H "Content-Type: application/json" \
  -d '{"question":"What is alpha-amylase used for?"}'
```

Response:
```json
{
  "results": [
    {
      "id": 1,
      "id_document": 1,
      "texte_fragment": "Alpha-Amylase (AMY1) - Baking Enzyme...",
      "score": 0.8601
    }
  ]
}
```

### Ingest Documents
**POST** `/ingest`

Request:
```bash
curl -X POST http://localhost:8000/ingest \
  -H "Content-Type: application/json" \
  -d '{
    "documents": [
      {
        "id": "doc_1",
        "text": "Your document text here..."
      }
    ]
  }'
```

Response:
```json
{
  "status": "success",
  "documents_ingested": 1
}
```

### Status Check
**GET** `/status`

```bash
curl http://localhost:8000/status
```

Response:
```json
{
  "status": "healthy",
  "total_documents": 4,
  "embedding_model": "all-MiniLM-L6-v2"
}
```

### Health Check
**GET** `/healthz`

```bash
curl http://localhost:8000/healthz
```

Response:
```json
{"status": "ok"}
```

---

## ğŸ“ Project Structure

```
challenge/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py              # FastAPI app + CLI
â”‚   â”œâ”€â”€ config.py            # Settings & environment
â”‚   â”œâ”€â”€ database.py          # ChromaDB wrapper
â”‚   â”œâ”€â”€ embeddings.py        # Sentence-Transformers integration
â”‚   â”œâ”€â”€ search_service.py    # Business logic for search/ingest
â”‚   â””â”€â”€ utils.py             # Helper utilities
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ enzymes/             # Document folder (4 sample documents)
â”‚   â”‚   â”œâ”€â”€ alpha_amylase.txt
â”‚   â”‚   â”œâ”€â”€ xylanase.txt
â”‚   â”‚   â”œâ”€â”€ ascorbic_acid.txt
â”‚   â”‚   â””â”€â”€ benzoyl_peroxide.txt
â”‚   â””â”€â”€ chroma_db/           # Vector store (auto-created)
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html           # Web frontend
â”œâ”€â”€ static/                  # (Empty, for future static assets)
â”œâ”€â”€ ingest_documents.py      # Standalone ingestion script
â”œâ”€â”€ .env                     # Local configuration
â”œâ”€â”€ .env.example             # Configuration template
â”œâ”€â”€ requirements.txt         # Python dependencies
â””â”€â”€ README.md                # This file
```

---

## ğŸ§ª How It Works

### 1. **Document Ingestion Flow**

```
.txt files in data/enzymes/
    â†“
ingest_documents.py (reads files)
    â†“
sentence-transformers (generates 384-dim embeddings)
    â†“
ChromaDB (stores embeddings + text)
    â†“
Vector store ready for search
```

### 2. **Semantic Search Flow**

```
User query in web interface (or API call)
    â†“
FastAPI /search endpoint
    â†“
sentence-transformers (generates query embedding)
    â†“
ChromaDB cosine similarity search
    â†“
Top 3 results with scores
    â†“
JSON response to frontend
    â†“
Display in web interface
```

---

## ğŸ“Š Sample Documents

The system includes 4 pre-configured sample bakery/enzyme documents:

1. **alpha_amylase.txt** - Enzyme dosing (50-300 ppm) and functions
2. **xylanase.txt** - Hemicellulase enzyme for bread quality
3. **ascorbic_acid.txt** - Oxidizing agent for dough conditioning
4. **benzoyl_peroxide.txt** - Flour bleaching and dough improver

These are automatically ingested on first run via `ingest_documents.py`.

---

## ğŸ”§ Configuration

Edit `.env` to customize:

```bash
# Vector store backend
DB_BACKEND=chroma

# ChromaDB storage path (relative or absolute)
CHROMA_DB_PATH=data/chroma_db

# Embedding model (MANDATORY - do not change per spec)
EMBEDDING_MODEL_NAME=all-MiniLM-L6-v2
```

---

## âš¡ Performance Notes

- **First search**: ~12 seconds (model loading, caching afterwards)
- **Subsequent searches**: ~1-2 seconds
- **Embedding generation**: All-MiniLM-L6-v2 handles 384D embeddings efficiently
- **Vector store**: ChromaDB uses HNSW for fast similarity search

---

## ğŸ§ª Testing

### Test Search Functionality
```bash
curl -X POST http://localhost:8000/search \
  -H "Content-Type: application/json" \
  -d '{"question":"Recommended dosages for enzyme improvers?"}'
```

### Test Ingestion
```bash
curl -X POST http://localhost:8000/ingest \
  -H "Content-Type: application/json" \
  -d '{"documents":[{"id":"test","text":"New enzyme document..."}]}'
```

### Verify Results
```bash
curl http://localhost:8000/status
```

---

## ğŸ“ Agent.md Requirements Met

âœ… Embedding model: `all-MiniLM-L6-v2` (384 dimensions)  
âœ… Similarity: Cosine similarity  
âœ… Top K: 3 results  
âœ… Clean modular architecture  
âœ… Production-ready code  
âœ… Error handling + logging  
âœ… CLI interface + REST API  
âœ… Config management with .env  
âœ… Document ingestion pipeline  

---

## ğŸ› Troubleshooting

### Server won't start
```bash
lsof -i :8000  # Check if port is in use
```

### Embedding model not downloading
- First run automatically downloads the model (~100MB)
- Ensure internet connectivity

### ChromaDB directory error
```bash
mkdir -p data/chroma_db
```

### Search returns no results
```bash
# Ensure documents are ingested
curl http://localhost:8000/status

# If needed, ingest documents
python3 ingest_documents.py
```

---

## ğŸ“š Resources

- [ChromaDB](https://docs.trychroma.com/)
- [Sentence-Transformers](https://www.sbert.net/)
- [FastAPI](https://fastapi.tiangolo.com/)
- [all-MiniLM-L6-v2](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2)

---

**Built for bakery & pastry formulation RAG assistance** âœ¨
